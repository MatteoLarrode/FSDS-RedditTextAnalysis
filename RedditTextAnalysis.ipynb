{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis of Subreddits - Collaborative Project\n",
    "\n",
    "The purpose of this project is to analyse the differences and similarities between different subreddits existing around a common topic. At first, we will collect Reddit data, analyse TF-IDF scores, and attempt to classify the subreddits using k-means and Naive Bayes algorithms. Then, we will introduce networks to visualise connections between threaded comments and users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Create README.md \n",
    "# pip3 install nbconvert\n",
    "# jupyter nbconvert --execute --to markdown RedditTextAnalysis.ipynb\n",
    "# then rename to README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I/ Collecting Reddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from config.settings import USER_AGENT\n",
    "from models.reddit_scraper import RedditScraper\n",
    "from utils.analysis import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_of_interest = ['islam', 'Christianity', 'atheism', 'Buddhism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraper = RedditScraper(USER_AGENT)\n",
    "\n",
    "# subs_of_interest = ['islam', 'atheism', 'Christianity', 'Buddhism']\n",
    "\n",
    "# results = {} \n",
    "\n",
    "# for sub in subs_of_interest:    \n",
    "#     posts = scraper.get_subreddit_posts(sub, limit=1000, cache=True)\n",
    "#     posts_df = create_posts_dataframe(posts)\n",
    "    \n",
    "#     tfidf_results = tfidf_analyze_subreddit(posts, include_selftext=True)\n",
    "#     # tfidf_results = tfidf_analyze_subreddit(posts)\n",
    "#     tf_idf_scores = get_mean_tfidf(\n",
    "#         tfidf_matrix=tfidf_results['tfidf_matrix'],\n",
    "#         feature_names=tfidf_results['feature_names'],\n",
    "#         return_df=True\n",
    "#     )\n",
    "#     results[sub] = {\"posts_df\":posts_df,\n",
    "#                     \"tfidf_results\":tfidf_results,\n",
    "#                     \"tf_idf_scores\":tf_idf_scores}\n",
    "\n",
    "# # Ensure the data directory exists\n",
    "# os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# # Just a backup of all the files, not used in the analysis directly\n",
    "# with open(\"data/results.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['islam', 'atheism', 'Christianity', 'Buddhism'])\n",
      "dict_keys(['posts_df', 'tfidf_results', 'tf_idf_scores'])\n",
      "I could be in the worst of the worst situations and I read maghrib then POOF its all gone, people who genuinely follow the religion are the best people unlike most people this gen vaping and going to parties thinking its cool.\n",
      "selftext\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     132\n",
      "Here is the link to the A Brief Illustrated Guide to Understanding Islam free online book: [https://www.islam-guide.com](https://www.islam-guide.com)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  4\n",
      "We hope you are all having a great Friday and hope you have a great week ahead!\\n\\nThis thread is for **casual discussion** only.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2\n",
      "\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     2\n",
      "Hello everyone,\\n\\nI am reaching out for any recommendations for websites/ reading material etc about the Islamic faith.\\n\\nI am a white male 35 years of age and faith is something I have been lacking in my life and I am looking for something to believe in.\\n\\nIslam has always been in my mind. Something about it feels , idk just right . I was interested in it on and off since I was around the age of 22.\\n\\nI never went too far into it because my family is a mixture of Christian Lutheran / or of no faith at all.\\n\\nIslam just feels right. However I would have to do this journey alone; I’m almost certain my family would not be accepting of me in ragers to this faith.\\n\\nI am asking all of you for guidance.\\n\\nWhere should I begin?\\n\\nI have listened to an audio version of the Holy Quran and it brings me inner peace. Where do I go from here?\\n\\nMay Allah bless all of you.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ... \n",
      "I have been talking with this boy for 2 years, last summer he blocked me because he had to work on himself. Then in September Allhamdulilah he came back to me. And just 6 days ago we had a small argument and I blocked him out of panic. I miss him and love him so much, and I regret my actions so much. I have done everything in my power to try to contact him but I am not getting a word. He was amazing for me, ands a good muslim and we would always talk about getting married and having a future. So the moment this happened Allah blessed me with the opportunity to get closer with him and I have been praying more often and on time, I pray tahajud, fast, do good deeds, say morning and evening adthkar  and constantly make dua and pray sunnah, for my dua to  be accepted. \\n\\nI know it's kind of wrong because im supposed to be doing it to get close to Allah, and not to get my dua accepted. But Its so hard, I miss and love him so much. I can't do anything, I have a big aching in my stomach and even if I try to focus on salad and  prayers about other things I can only think about him. I want to be genuine but I can't. I also leanred that Allah said \" I am what my servant thinks of me\" so if I truly believe that Allah can bring him and me back in connection, it can happen. But I dont know if it's me or the shaitan telling me that it can't happen.  And I also read another muslimah's story and she said something a long the lines of 'Allah won't make me beg and cry for something he won't give me' And that's all I do, beg and cry to Allah for him to come back to me. Im failing school, and I need him. I love Allah, but its so hard to have certainty that Allahrespond and make my dua come true, because I have so many doubts, how do I get rid of that?      1\n",
      "Asalamualaykum,\\nI am asking if this is permissable or if it is discouraged. I am a sister and I work at a hospital that has a prayer room. Some men pray a jummah prayer together but I don't think there are any other muslim women, who at least can join. If im the only sister there can I pray jummah with them or should I just pray dhuhr on my own either before or after them? It's one large room, not separated by gender.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
      "Salam, \\n\\nI have an agnostic friend that I discuss religion with.\\n\\nShe has 2 main problems with Islam.\\n\\n1- She says the idea of hell is too harsh and gives her anxiety. \\n\\n2- Religion in general was for an uncivilized time and not necessary anymore \\n\\nHelp me in my dawah please \\n\\nJazakallah                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1\n",
      "I have seen a few different brothers and sisters making videos on whether Halloween is halal or haram, etc. I’d like to share this I found instead on a Hadith we can all reflect on. Jazak Allah Khair. \\n\\nAbu Huraira reported: The Prophet, peace and blessings be upon him, said, “Your fire, which the son of Adam ignites, is only one of seventy parts from the fire of Hell.” They said, “By Allah, that would be enough, O Messenger of Allah!” The Prophet said, “Verily, it exceeds it by sixty nine parts, each of which are like its heat.”\\n\\nSource: Ṣaḥīḥ Muslim 2843\\n\\nGrade: Sahih (authentic agreed upon) according to Muslim\\n\\nعَنْ أَبِي هُرَيْرَةَ أَنَّ النَّبِيَّ صَلَّى اللهُ عَلَيْهِ وَسَلَّمَ قَالَ نَارُكُمْ هَذِهِ الَّتِي يُوقِدُ ابْنُ آدَمَ جُزْءٌ مِنْ سَبْعِينَ جُزْءًا مِنْ حَرِّ جَهَنَّمَ قَالُوا وَاللهِ إِنْ كَانَتْ لَكَافِيَةً يَا رَسُولَ اللهِ قَالَ فَإِنَّهَا فُضِّلَتْ عَلَيْهَا بِتِسْعَةٍ وَسِتِّينَ جُزْءًا كُلُّهَا مِثْلُ حَرِّهَا\\n\\n2843 صحيح مسلم كتاب الجنة وصفة نعيمها وأهلها باب في شدة حر نار جهنم وبعد قعرها وما تأخذ من المعذبين                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
      "Some people i know use this to commit shirk. Like praying to someone else asking for help other than allah azzawajal. However in this ayah allah azzawajal says take to guardianship in allah, his messenger and beleivers. Im a bit confused. Can someone please provide a correct explanation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1\n",
      "Name: count, Length: 817, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Code to open the pickle\n",
    "with open(\"data/results.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "print(results.keys())\n",
    "print(results['islam'].keys())\n",
    "print(results['islam']['posts_df']['selftext'][1])\n",
    "print(results['islam']['posts_df']['selftext'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II/ Initial Similarity Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the vocabulary for each subreddit\n",
    "vocabularies = {sub: set(results[sub]['tfidf_results']['feature_names']) for sub in subs_of_interest}\n",
    "\n",
    "# Get the intersection of the vocabularies\n",
    "common_vocab = set.intersection(*vocabularies.values())\n",
    "\n",
    "# Report analytics\n",
    "print(f\"Number of common terms across all subreddits: {len(common_vocab)}\")\n",
    "print(f\"Common terms: {', '.join(list(common_vocab)[:10])}...\")  # Display first 10 common terms\n",
    "\n",
    "# Calculate Jaccard similarity for each pair of subreddits\n",
    "for sub1 in subs_of_interest:\n",
    "    for sub2 in subs_of_interest:\n",
    "        if sub1 > sub2:\n",
    "            intersection = vocabularies[sub1].intersection(vocabularies[sub2])\n",
    "            union = vocabularies[sub1].union(vocabularies[sub2])\n",
    "            jaccard_similarity = len(intersection) / len(union)\n",
    "            print(f\"Jaccard similarity between {sub1} and {sub2}: {jaccard_similarity:.3f}\")\n",
    "\n",
    "# Report unique terms for each subreddit\n",
    "for sub in subs_of_interest:\n",
    "    unique_terms = vocabularies[sub] - common_vocab\n",
    "    print(f\"Number of unique terms in {sub}: {len(unique_terms)}\")\n",
    "    print(f\"Unique terms in {sub}: {', '.join(list(unique_terms)[:10])}...\")  # Display first 10 unique terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Word Similarities #1: MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analysis import plot_word_similarities_mds\n",
    "\n",
    "for sub in subs_of_interest:\n",
    "    plot_word_similarities_mds(results[sub]['tfidf_results']['tfidf_matrix'], \n",
    "                               results[sub]['tfidf_results']['feature_names'],\n",
    "                               n_terms=20,\n",
    "                               title=sub)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the word similarities #2: Using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analysis import plot_word_similarities_tsne\n",
    "\n",
    "for sub in subs_of_interest:\n",
    "    fig, ax = plot_word_similarities_tsne(results[sub]['tfidf_results']['tfidf_matrix'], \n",
    "                                     results[sub]['tfidf_results']['feature_names'],\n",
    "                                     n_highlight=20,\n",
    "                                     title=sub)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III/ Believe vs. Knowing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for extracting monthly posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define months in 2024 up to the current month\n",
    "start_dates = [datetime(2024, month, 1) for month in range(1, 12)]\n",
    "end_dates = [datetime(2024, month + 1, 1) if month < 12 else datetime(2024, 12, 31) for month in range(1, 12)]\n",
    "\n",
    "scraper = RedditScraper_monthly(USER_AGENT)\n",
    "\n",
    "# Dictionary to store posts for each subreddit across all months\n",
    "all_posts = {sub: [] for sub in subs_of_interest}\n",
    "\n",
    "# Loop through each month to collect posts\n",
    "for sub in subs_of_interest:\n",
    "    for start, end in zip(start_dates, end_dates):\n",
    "        month_name = start.strftime(\"%B\")\n",
    "        print(f\"Scraping {sub} for {month_name} 2024...\")\n",
    "        \n",
    "        # Scrape posts for the specific month\n",
    "        posts = scraper.get_subreddit_posts(sub, limit=100, cache=True, after=start, before=end)\n",
    "        \n",
    "        # Append the monthly posts to the subreddit-specific list\n",
    "        all_posts[sub].extend(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning all 40 JSOns into four dataframes \n",
    "# Directory where JSON files are stored\n",
    "cache_dir = 'cache'\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Loop through each subreddit to combine JSON files into one DataFrame\n",
    "for sub in subs_of_interest:\n",
    "    json_files = [f for f in os.listdir(cache_dir) if f.startswith(sub) and f.endswith('.json')]\n",
    "    \n",
    "    # List to collect individual DataFrames for each month\n",
    "    monthly_data = []\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        with open(os.path.join(cache_dir, json_file), 'r') as f:\n",
    "            data = json.load(f)\n",
    "            df = pd.DataFrame(data)\n",
    "            monthly_data.append(df)\n",
    "    \n",
    "    # Concatenate all monthly data into a single DataFrame for the subreddit\n",
    "    dataframes[sub] = pd.concat(monthly_data, ignore_index=True)\n",
    "\n",
    "# Clean up by removing variables that aren’t needed\n",
    "del cache_dir, subs_of_interest, sub, json_files, monthly_data, json_file, f, data, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract each topic's DataFrame from the dataframes dictionary for a better overview\n",
    "df_islam = dataframes['islam']\n",
    "df_christianity = dataframes['Christianity']\n",
    "df_atheism = dataframes['atheism']\n",
    "df_buddhism = dataframes['Buddhism']\n",
    "\n",
    "# Note that for the rest of the code to work these dataframes need to be saved as \"df_something\" (i.e., start with df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform TFIDF analysis on aggregated posts for each subreddit\n",
    "for sub, posts in all_posts.items():\n",
    "    print(f\"\\nConducting TFIDF analysis on all posts for {sub} in 2024...\")\n",
    "\n",
    "    # Create a DataFrame for the aggregated posts\n",
    "    posts_df = create_posts_dataframe(posts)\n",
    "    \n",
    "    # Conduct TFIDF analysis\n",
    "    tfidf_results = tfidf_analyze_subreddit(posts)\n",
    "    tf_idf_scores = get_mean_tfidf(\n",
    "        tfidf_matrix=tfidf_results['tfidf_matrix'],\n",
    "        feature_names=tfidf_results['feature_names'],\n",
    "        return_df=True\n",
    "    )\n",
    "    \n",
    "    # Get top 10 terms for each subreddit\n",
    "    top_terms = get_top_terms(tf_idf_scores, n_terms=10)\n",
    "    print(f\"The top 10 terms for {sub} in 2024 are:\\n\", \"\\n\".join(top_terms), sep=\"\")\n",
    "    display(tf_idf_scores.head().style.format(\"{:.3f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'datetime' column for each DataFrame that ends in '_df' (increases reusability)\n",
    "for name, df in list(globals().items()):\n",
    "    if name.startswith('df_') and isinstance(df, pd.DataFrame):\n",
    "        df['datetime'] = pd.to_datetime(df['created_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
